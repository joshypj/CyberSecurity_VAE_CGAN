{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f89f589-9462-4e04-9beb-b177a82077b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.load(\"../data/preserve100/x_train.npy\")\n",
    "y_train = np.load(\"../data/preserve100/y_train.npy\")\n",
    "x_test = np.load(\"../data/preserve100/x_test.npy\")\n",
    "y_test = np.load(\"../data/preserve100/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e325a7d-9b7c-4096-9e4d-93db912d613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 24.0 from /work1/anaconda3/envs/upgrad_3812/lib/python3.8/site-packages/pip (python 3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip -V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0ec836-856f-4585-b9ae-e401effdee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (2120907, 31)\n",
      "y_train (2120907, 1)\n",
      "x_test (706969, 31)\n",
      "y_test (706969, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81270bd0-edab-4446-8027-fa7863210541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,015</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vae_loss_layer_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VAELossLayer</span>)      │                   │            │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,048\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,112\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)        │      \u001b[38;5;34m2,015\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vae_loss_layer_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mVAELossLayer\u001b[0m)      │                   │            │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,335</span> (40.37 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,335\u001b[0m (40.37 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,335</span> (40.37 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,335\u001b[0m (40.37 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 1/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: nan - val_accuracy: 0.8034 - val_loss: nan\n",
      "Epoch 2/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: nan - val_accuracy: 0.8034 - val_loss: nan\n",
      "Epoch 3/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.8032 - loss: nan - val_accuracy: 0.8034 - val_loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: nan - val_accuracy: 0.8034 - val_loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: nan - val_accuracy: 0.8034 - val_loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: nan - val_accuracy: 0.8034 - val_loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: nan - val_accuracy: 0.8034 - val_loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: nan - val_accuracy: 0.8034 - val_loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.8035 - loss: nan - val_accuracy: 0.8034 - val_loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m14913/14913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: nan - val_accuracy: 0.8034 - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f90e0686960>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load preprocessed data\n",
    "# x_train = np.load(\"../data/preserve10/x_train.npy\")\n",
    "# y_train = np.load(\"../data/preserve10/y_train.npy\")\n",
    "\n",
    "# Define VAE parameters\n",
    "original_dim = x_train.shape[1]\n",
    "intermediate_dim = 64\n",
    "latent_dim = 32\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# VAE Encoder\n",
    "inputs = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "# Sampling layer\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# Decoder\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# Define the VAE model\n",
    "vae = Model(inputs, x_decoded_mean)\n",
    "\n",
    "# Custom VAE Loss Layer\n",
    "class VAELossLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(VAELossLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x, x_decoded_mean, z_mean, z_log_var = inputs\n",
    "        reconstruction_loss = tf.reduce_sum(tf.keras.losses.binary_crossentropy(x, x_decoded_mean), axis=-1)\n",
    "        kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        self.add_loss(tf.reduce_mean(reconstruction_loss + kl_loss))\n",
    "        return x_decoded_mean\n",
    "\n",
    "# Apply the VAE loss layer\n",
    "vae_output = VAELossLayer()([inputs, x_decoded_mean, z_mean, z_log_var])\n",
    "vae = Model(inputs, vae_output)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n",
    "\n",
    "# Train VAE\n",
    "vae.fit(x_train, x_train, epochs=10, batch_size=128,validation_split=0.1)\n",
    "\n",
    "# Classifier using the VAE latent space\n",
    "class VAEClassifier(Model):\n",
    "    def __init__(self, vae, latent_dim, num_classes):\n",
    "        super(VAEClassifier, self).__init__()\n",
    "        self.vae_encoder = Model(vae.input, vae.get_layer(index=-3).output)\n",
    "        self.classifier = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z = self.vae_encoder(inputs)\n",
    "        return self.classifier(z)\n",
    "\n",
    "# Build the classifier\n",
    "classifier = VAEClassifier(vae, latent_dim, num_classes)\n",
    "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train classifier on VAE latent space\n",
    "classifier.fit(x_train, y_train, epochs=10, batch_size=128,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c819ba2-939e-46b1-b121-de3a021452d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy\n",
      "66279/66279 - 66s - 993us/step - accuracy: 0.8030 - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.8030012845993042]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train Accuracy\")\n",
    "classifier.evaluate(x_train, \n",
    "               y_train, \n",
    "               verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e871888e-59d4-49b7-ba12-e939b1dc55ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy\n",
      "22093/22093 - 22s - 995us/step - accuracy: 0.8038 - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.8037537932395935]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test Accuracy\")\n",
    "classifier.evaluate(x_test, \n",
    "               y_test, \n",
    "               verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25ecd38e-6eac-4a7d-8aa3-c13ee5d840ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22093/22093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8038    1.0000    0.8912    568229\n",
      "           1     0.0000    0.0000    0.0000       484\n",
      "           2     0.0000    0.0000    0.0000     31818\n",
      "           3     0.0000    0.0000    0.0000      2529\n",
      "           4     0.0000    0.0000    0.0000     57561\n",
      "           5     0.0000    0.0000    0.0000      1318\n",
      "           6     0.0000    0.0000    0.0000      1463\n",
      "           7     0.0000    0.0000    0.0000      1995\n",
      "           8     0.0000    0.0000    0.0000         4\n",
      "           9     0.0000    0.0000    0.0000         7\n",
      "          10     0.0000    0.0000    0.0000     39566\n",
      "          11     0.0000    0.0000    0.0000      1452\n",
      "          12     0.0000    0.0000    0.0000       377\n",
      "          13     0.0000    0.0000    0.0000         4\n",
      "          14     0.0000    0.0000    0.0000       162\n",
      "\n",
      "    accuracy                         0.8038    706969\n",
      "   macro avg     0.0536    0.0667    0.0594    706969\n",
      "weighted avg     0.6460    0.8038    0.7163    706969\n",
      "\n",
      "Weighted Precision: 64.60%\n",
      "Weighted Recall: 80.38%\n",
      "Weighted F1-Score: 71.63%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Get predictions\n",
    "y_test_pred = classifier.predict(x_test)\n",
    "\n",
    "# If the model outputs probabilities, convert them to class labels\n",
    "y_test_pred_labels = y_test_pred.argmax(axis=1)  # Assuming output is one-hot encoded or probabilities\n",
    "\n",
    "# Flatten y_test if it is a pandas DataFrame or multi-dimensional\n",
    "if isinstance(y_test, pd.DataFrame):  # Check if y_test is a pandas DataFrame\n",
    "    y_test = y_test.to_numpy().ravel()\n",
    "elif len(y_test.shape) > 1:\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "# Calculate and print precision, recall, and F1-score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_labels, digits=4))\n",
    "\n",
    "# Optionally, calculate overall metrics in percentage\n",
    "precision = precision_score(y_test, y_test_pred_labels, average='weighted') * 100\n",
    "recall = recall_score(y_test, y_test_pred_labels, average='weighted') * 100\n",
    "f1 = f1_score(y_test, y_test_pred_labels, average='weighted') * 100\n",
    "\n",
    "print(f\"Weighted Precision: {precision:.2f}%\")\n",
    "print(f\"Weighted Recall: {recall:.2f}%\")\n",
    "print(f\"Weighted F1-Score: {f1:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34cabd7b-f243-4aae-a0b1-fcfd837b8c46",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take the length of shape with unknown rank.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test data (you can also use x_train and y_train to evaluate training accuracy)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n",
      "File \u001b[0;32m/work1/anaconda3/envs/vae-cgan/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/work1/anaconda3/envs/vae-cgan/lib/python3.12/site-packages/keras/src/losses/loss.py:107\u001b[0m, in \u001b[0;36msqueeze_or_expand_to_same_rank\u001b[0;34m(x1, x2, expand_rank_1)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msqueeze_or_expand_to_same_rank\u001b[39m(x1, x2, expand_rank_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Squeeze/expand last dim if ranks differ from expected by exactly 1.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     x1_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    108\u001b[0m     x2_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x2\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x1_rank \u001b[38;5;241m==\u001b[39m x2_rank:\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take the length of shape with unknown rank."
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data (you can also use x_train and y_train to evaluate training accuracy)\n",
    "loss, accuracy = classifier.evaluate(x_test, y_test, batch_size=128)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = classifier.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the test labels\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Dashed line for random guessing\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Each Class')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred_classes)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc32fc7-8c4b-4735-9e4d-1fce7971c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "z_val = classifier.vae_encoder.predict(x_val)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "cosine_sim_matrix = cosine_similarity(z_val)\n",
    "\n",
    "# Example: Get average cosine similarity for each sample\n",
    "avg_cosine_sim = np.mean(cosine_sim_matrix, axis=1)\n",
    "print(\"Average Cosine Similarity per sample:\", avg_cosine_sim)\n",
    "\n",
    "\n",
    "# 1. Plotting the Distribution of Cosine Similarities\n",
    "# A histogram or KDE (Kernel Density Estimate) plot can reveal the spread of cosine similarities, indicating how closely samples are grouped in the latent space.\n",
    "# Interpretation: A higher average cosine similarity suggests that samples are more clustered in the latent space. A tight clustering could indicate that the VAE encoder\n",
    "# has learned meaningful features, while a wider spread might suggest that further tuning is needed.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Plot the distribution of average cosine similarities\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(avg_cosine_sim, kde=True, bins=30, color=\"skyblue\")\n",
    "plt.title(\"Distribution of Average Cosine Similarities in Latent Space\")\n",
    "plt.xlabel(\"Cosine Similarity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# A heatmap of cosine similarities can visualize sample relationships. For simplicity, this example uses the first 20 samples in z_val.\n",
    "# Interpretation: Similar samples should have higher cosine similarity values (closer to 1). You can look for high-similarity clusters \n",
    "# in the heatmap, which would suggest that certain samples share similar features in the latent space.\n",
    "\n",
    "# Generate a cosine similarity matrix heatmap for the first 20 samples\n",
    "subset_cosine_sim_matrix = cosine_sim_matrix[:20, :20]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(subset_cosine_sim_matrix, annot=True, cmap=\"coolwarm\", cbar=True)\n",
    "plt.title(\"Cosine Similarity Heatmap (Sample Subset)\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761decd2-3d97-42dd-a20f-81fa75e0ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from predictions import make_prediction, PredMetrics, get_prediction_metrics, labels\n",
    "print(\"Test Model Detailed Report\")\n",
    "x_test = pd.DataFrame(x_test)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "predictions = make_prediction(classifier, x_test, y_test)\n",
    "pred_metrics = get_prediction_metrics(predictions)\n",
    "\n",
    "\n",
    "print(\"FP Rate (FPR):\", round(pred_metrics.weighted_fpr, 4))\n",
    "print(\"FN Rate (FNR):\", round(pred_metrics.weighted_fnr, 4))\n",
    "print(\"Detection Rate:\", round(pred_metrics.weighted_detection_rate, 4))\n",
    "print(\"False Alarm Rate (FAR):\", round(pred_metrics.false_alarm_rate, 4))\n",
    "print(\"Accuracy: \", round(pred_metrics.classification_report.loc[\"accuracy\"].iloc[0], 4))\n",
    "\n",
    "pred_metrics.classification_report.columns = [\"Precision\", \"Recall\", \"F1-score\", \"Quantity\"]\n",
    "pred_metrics.classification_report = pred_metrics.classification_report.astype({\"Quantity\": int})\n",
    "pred_metrics.classification_report.drop(\"accuracy\", axis=0, inplace=True)\n",
    "\n",
    "print(\"\\n\", pred_metrics.classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c80ee-4e9c-4ed4-8f80-f37bbc825c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca3fe2-1571-4665-8c0b-15992f923da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, LSTM, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load and preprocess the data\n",
    "# Assuming you already have the x_train, y_train, x_test, y_test as numpy arrays\n",
    "\n",
    "# Encode the labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Apply SMOTE for balancing the dataset\n",
    "smote1 = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=1)\n",
    "smote2 = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=1)\n",
    "\n",
    "x_train_resampled, y_train_resampled = smote1.fit_resample(x_train, y_train_encoded)\n",
    "x_test_resampled, y_test_resampled = smote2.fit_resample(x_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede22f9d-d78e-4ff1-bfb7-107fa69f5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_resampled = x_train \n",
    "x_test_resampled = x_test\n",
    "# VAE Encoder Model\n",
    "def build_vae_encoder(latent_dim):\n",
    "    input_layer = Input(shape=(x_train.shape[1],))  # Input layer\n",
    "    x = Dense(256, activation='relu')(input_layer)  # Hidden layer\n",
    "    x = Dense(128, activation='relu')(x)  # Hidden layer\n",
    "    z_mean = Dense(latent_dim)(x)  # Mean of latent space\n",
    "    z_log_var = Dense(latent_dim)(x)  # Log variance of latent space\n",
    "    encoder = Model(input_layer, [z_mean, z_log_var])\n",
    "    return encoder\n",
    "\n",
    "# VAE Decoder Model\n",
    "def build_vae_decoder(latent_dim):\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = Dense(128, activation='relu')(latent_inputs)  # Hidden layer\n",
    "    x = Dense(256, activation='relu')(x)  # Hidden layer\n",
    "    decoded = Dense(x_train.shape[1], activation='sigmoid')(x)  # Output layer\n",
    "    decoder = Model(latent_inputs, decoded)\n",
    "    return decoder\n",
    "\n",
    "# CGAN Generator Model (for data generation)\n",
    "def build_cgan_generator(latent_dim):\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = Dense(256, activation='relu')(latent_inputs)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    generated_data = Dense(x_train.shape[1], activation='sigmoid')(x)\n",
    "    generator = Model(latent_inputs, generated_data)\n",
    "    return generator\n",
    "\n",
    "# CGAN Discriminator Model (for classification)\n",
    "def build_cgan_discriminator():\n",
    "    input_layer = Input(shape=(x_train.shape[1],))\n",
    "    x = Dense(256, activation='relu')(input_layer)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(input_layer, output)\n",
    "    discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return discriminator\n",
    "\n",
    "# VAE-CGAN Hybrid Model\n",
    "def build_vaecgan_hybrid(latent_dim):\n",
    "    encoder = build_vae_encoder(latent_dim)\n",
    "    decoder = build_vae_decoder(latent_dim)\n",
    "    generator = build_cgan_generator(latent_dim)\n",
    "    discriminator = build_cgan_discriminator()\n",
    "\n",
    "    # Define the VAE loss\n",
    "    def vae_loss(x, decoded):\n",
    "        xent_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(x, decoded))\n",
    "        return xent_loss\n",
    "    \n",
    "    # VAE Encoder + Decoder Model\n",
    "    vae = Model(encoder.input, decoder(encoder.output[0]))  # Using the z_mean from encoder\n",
    "    vae.compile(optimizer=Adam(learning_rate=0.0002), loss=vae_loss)\n",
    "    \n",
    "    # CGAN Generator + Discriminator Model (adversarial model)\n",
    "    z = Input(shape=(latent_dim,))\n",
    "    generated_data = generator(z)\n",
    "    discriminator_output = discriminator(generated_data)\n",
    "    cgan = Model(z, discriminator_output)\n",
    "    cgan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return vae, cgan\n",
    "\n",
    "# Define latent dimension for the VAE\n",
    "latent_dim = 100\n",
    "\n",
    "# Build the VAE-CGAN hybrid model\n",
    "print(\"Build the VAE-CGAN hybrid model\")\n",
    "vae, cgan = build_vaecgan_hybrid(latent_dim)\n",
    "\n",
    "# Train the VAE model first\n",
    "print(\"Train the VAE model first\")\n",
    "vae.fit(x_train_resampled, x_train_resampled, epochs=1, batch_size=64)\n",
    "\n",
    "# Train the CGAN model (discriminator and generator)\n",
    "print(\"Train the CGAN model (discriminator and generator)\")\n",
    "z_fake = np.random.normal(0, 1, (x_train_resampled.shape[0], latent_dim))\n",
    "cgan.fit(z_fake, np.ones((x_train_resampled.shape[0], 1)), epochs=1, batch_size=64)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Evaluate the model\")\n",
    "# vae.evaluate(x_test_resampled, x_test_resampled)\n",
    "# cgan.evaluate(z_fake, np.ones((x_test_resampled.shape[0], 1)))\n",
    "\n",
    "# Extract the encoder from the VAE model\n",
    "print(\"Extract the encoder from the VAE model\")\n",
    "encoder = vae.layers[0]   # Access the encoder model directly (this will be the second layer)\n",
    "print(encoder)\n",
    "\n",
    "# # Get the mean (z_mean) from the encoder output\n",
    "# print(\"Get the mean (z_mean) from the encoder output\")\n",
    "# # z_mean, _ = encoder.predict(x_train_resampled)\n",
    "# z_mean, _, _ = encoder.predict(x_train_resampled)\n",
    "\n",
    "# Now, use the encoder part of the VAE for feature extraction\n",
    "encoded_data = vae.layers[0]('encoder')(x_train_resampled)\n",
    "\n",
    "# Now, use the encoded data to train a classifier\n",
    "classifier = Dense(64, activation='relu')(encoded_data)\n",
    "classifier = Dense(15, activation='softmax')(classifier)  # 15 classes\n",
    "classifier_model = Model(inputs=vae.input, outputs=classifier)\n",
    "classifier_model.compile(optimizer=Adam(learning_rate=0.0002), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the classifier\n",
    "classifier_model.fit(x_train_resampled, y_train_resampled, epochs=1, batch_size=64)\n",
    "\n",
    "# Evaluate the classifier\n",
    "classifier_model.evaluate(x_test_resampled, y_test_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7564a9d8-4304-47e0-a595-d12dddf63e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the VAE Encoder Model\n",
    "def build_vae_encoder(latent_dim):\n",
    "    input_layer = Input(shape=(x_train.shape[1],))  # Input layer\n",
    "    x = Dense(256, activation='relu')(input_layer)  # Hidden layer\n",
    "    x = Dense(128, activation='relu')(x)  # Hidden layer\n",
    "    z_mean = Dense(latent_dim)(x)  # Mean of latent space\n",
    "    z_log_var = Dense(latent_dim)(x)  # Log variance of latent space\n",
    "    encoder = Model(input_layer, [z_mean, z_log_var])\n",
    "    return encoder\n",
    "\n",
    "# Build the VAE Decoder Model\n",
    "def build_vae_decoder(latent_dim):\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = Dense(128, activation='relu')(latent_inputs)  # Hidden layer\n",
    "    x = Dense(256, activation='relu')(x)  # Hidden layer\n",
    "    decoded = Dense(x_train.shape[1], activation='sigmoid')(x)  # Output layer\n",
    "    decoder = Model(latent_inputs, decoded)\n",
    "    return decoder\n",
    "\n",
    "# Build the CGAN Generator Model\n",
    "def build_cgan_generator(latent_dim):\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = Dense(256, activation='relu')(latent_inputs)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    generated_data = Dense(x_train.shape[1], activation='sigmoid')(x)\n",
    "    generator = Model(latent_inputs, generated_data)\n",
    "    return generator\n",
    "\n",
    "# Build the CGAN Discriminator Model\n",
    "def build_cgan_discriminator():\n",
    "    input_layer = Input(shape=(x_train.shape[1],))\n",
    "    x = Dense(256, activation='relu')(input_layer)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(input_layer, output)\n",
    "    discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return discriminator\n",
    "\n",
    "# VAE-CGAN Hybrid Model\n",
    "def build_vaecgan_hybrid(latent_dim):\n",
    "    encoder = build_vae_encoder(latent_dim)\n",
    "    decoder = build_vae_decoder(latent_dim)\n",
    "    generator = build_cgan_generator(latent_dim)\n",
    "    discriminator = build_cgan_discriminator()\n",
    "\n",
    "    # VAE loss (Reconstruction + KL Divergence)\n",
    "    def vae_loss(x, decoded, z_mean, z_log_var):\n",
    "        xent_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(x, decoded))\n",
    "        kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "        return xent_loss + kl_loss\n",
    "    \n",
    "    vae = Model(encoder.input, decoder(encoder.output[0]))  # VAE model\n",
    "    vae.compile(optimizer=Adam(learning_rate=0.0002), loss=lambda x, y: vae_loss(x, y, encoder.output[0], encoder.output[1]))\n",
    "    \n",
    "    z = Input(shape=(latent_dim,))\n",
    "    generated_data = generator(z)\n",
    "    discriminator_output = discriminator(generated_data)\n",
    "    cgan = Model(z, discriminator_output)\n",
    "    cgan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return vae, cgan, encoder, decoder, generator, discriminator\n",
    "\n",
    "# Training function\n",
    "def train_vaecgan_hybrid(epochs=1, batch_size=64):\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        idx = np.random.randint(0, x_train_resampled.shape[0], batch_size)\n",
    "        real_data = x_train_resampled[idx]\n",
    "        \n",
    "        z_mean, z_log_var = encoder.predict(real_data)\n",
    "        generated_data = generator.predict(z_mean)\n",
    "        \n",
    "        vae_loss_value = vae.train_on_batch(real_data, real_data)\n",
    "        \n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch(real_data, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_data, fake_labels)\n",
    "        \n",
    "        z_fake = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = cgan.train_on_batch(z_fake, real_labels)\n",
    "        \n",
    "        # Validation phase\n",
    "        z_mean_val, z_log_var_val = encoder.predict(x_val_resampled)\n",
    "        generated_data_val = generator.predict(z_mean_val)\n",
    "        val_vae_loss = vae.evaluate(x_val_resampled, x_val_resampled, batch_size=batch_size)\n",
    "        val_d_loss_real = discriminator.evaluate(x_val_resampled, np.ones((x_val_resampled.shape[0], 1)), batch_size=batch_size)\n",
    "        val_d_loss_fake = discriminator.evaluate(generated_data_val, np.zeros((generated_data_val.shape[0], 1)), batch_size=batch_size)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - VAE Loss: {vae_loss_value}, D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, G Loss: {g_loss[0]}\")\n",
    "        print(f\"Validation - VAE Loss: {val_vae_loss[0]}, D Loss Real: {val_d_loss_real[0]}, D Loss Fake: {val_d_loss_fake[0]}\")\n",
    "\n",
    "# Define latent dimension for the VAE\n",
    "latent_dim = 100\n",
    "\n",
    "# Build the VAE-CGAN hybrid model\n",
    "print(\"Building the VAE-CGAN hybrid model...\")\n",
    "vae, cgan, encoder, decoder, generator, discriminator = build_vaecgan_hybrid(latent_dim)\n",
    "\n",
    "# Start training the VAE-CGAN hybrid model\n",
    "print(\"Training the VAE-CGAN hybrid model...\")\n",
    "train_vaecgan_hybrid(epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1950ac2-f259-437d-b699-300c453f5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier\n",
    "classifier_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2f81c-6c5c-495d-b4ea-4536dcc1ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = classifier_model.predict(x_test)  # Uncomment this line to use your trained model for predictions\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae-cgan",
   "language": "python",
   "name": "vae-cgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
